//--------------------------------------------------------------------------------

-------------- Build: Debug in TestArm (compiler: GNU GCC Compiler)---------------

g++ -Wall -fexceptions pkg-config opencv4 -g -I../../../../../../../usr/include/opencv4/opencv2
-c /media/ghost/559787AD42546355/Projects/CurrentProjects/Linux/TestArm/main.cpp
-o obj/Debug/main.o
g++  -o bin/Debug/TestArm obj/Debug/main.o
/media/ghost/559787AD42546355/Projects/CurrentProjects/Linux/TestArm/main.cpp:14:10:
fatal error: ../../../../../../../usr/include/opencv4/opencv2: No such file or directory
   14 | #include "../../../../../../../usr/include/opencv4/opencv2"
      |          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
Process terminated with status 1 (0 minute(s), 0 second(s))
1 error(s), 0 warning(s) (0 minute(s), 0 second(s))


-------------- Build: Debug in TestArm (compiler: GNU GCC Compiler)---------------

g++ -L../../../../../../../usr/include/opencv4/opencv2 -o bin/Debug/TestArm obj/Debug/main.o   ../../../../../../../usr/lib/x86_64-linux-gnu/libopencv_highgui.so
/usr/bin/ld: obj/Debug/main.o: undefined reference to symbol '_ZN2cv6imreadERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEi'
/usr/bin/ld: /lib/x86_64-linux-gnu/libopencv_imgcodecs.so.4.5d: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status
Process terminated with status 1 (0 minute(s), 0 second(s))
2 error(s), 0 warning(s) (0 minute(s), 0 second(s))

//--------------------------------------------------------------------------------
/usr/lib/x86_64-linux-gnu/libopencv_imgcodecs.so
/usr/lib/x86_64-linux-gnu/libopencv_highgui.so
/usr/lib/x86_64-linux-gnu/libopencv_core.so
/usr/lib/x86_64-linux-gnu/libopencv_imgproc.so

ну наконец то! подключил /usr/lib/x86_64-linux-gnu/libopencv_core.so в настройках проекта codeblocks и заработало. пропала ошибка: undefined reference to symbol '_ZN2cv6imreadERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEi'
/usr/bin/ld: /lib/x86_64-linux-gnu/libopencv_imgcodecs.so.4.5d: error adding symbols: DSO missing from command line
collect2: error: ld returned 1 exit status. с codeblocks многое нужно делать вручную. но мне эта ide очень нравится и пока не хочу переходить на голый make.  спасибо за помощь и выдержку.

//--------------------------------------------------------------------------------
/usr/bin/ld: cannot find obj/Debug/examples/main.o: No such file or directory
нужно подключать поиск директорий в соответствии с путями к заголовкам в файлах.
#include "EasyCNN/EasyCNN.h"
/home/ghost/Documents/EasyCNN/header

ошибки:
/usr/bin/ld: cannot find obj/Debug/examples/main.o: No such file or directory
/usr/bin/ld: cannot find obj/Debug/examples/mnist/mnist_data_loader.o: No such file or directory
/usr/bin/ld: cannot find obj/Debug/examples/mnist/mnist_train_test.o: No such file or directory
в файле проекта заменил:
		<Build>
			<Target title="Debug">
				<Option output="bin/Debug/EasyCNN" prefix_auto="1" extension_auto="1" />
				<Option object_output="obj/Debug/" />
на
		<Build>
			<Target title="Debug">
				<Option output="bin/Debug/EasyCNN" prefix_auto="1" extension_auto="1" />
				<Option object_output="/media/ghost/559787AD42546355/Projects/Информатика/Машинное обучение/Свёрточные нейросети/EasyCNN-master/EasyCNN/obj/Debug/" />

//--------------------------------------------------------------------------------
подключил библиотеку: /usr/lib/x86_64-linux-gnu/libopencv_imgproc.so, несколько заголовочных, удалил из проекта сборки: dirent.h,utils.h, изменил: CV_THRESH_BINARY на  cv::THRESH_BINARY и о чудо! проект: EasyCNN собрался под линукс, без использования visualstudio.

//--------------------------------------------------------------------------------
сборка происходит нормально и на ntfs и ext4 на всех разделах, и попутям с кирилицей.
с разными файлами проекта .cbp но в одной рабочей папке, даже с разными именами.
вероятно файл проекта .cbp не оказывает влияния.
в чём может быть дело?
подкинул папку: obj и всё собралось нормально.
проблема в том, что компилятор не работает по путям с кирилицей.


//--------------------------------------------------------------------------------
optimize network train/test speed, use cuBLAS/OpenBLAS etc.
https://neurohive.io/ru/osnovy-data-science/

//--------------------------------------------------------------------------------
Чтобы удалить OpenCV в Ubuntu, используйте следующие шаги:

    Удалите OpenCV с помощью apt:

sudo apt-get remove --purge libopencv*

    Удалите дополнительные зависимости OpenCV:

sudo apt-get autoremove

    Проверьте и удалите оставшиеся файлы:

sudo rm -rf /usr/local/lib/python3.8/dist-packages/cv2*
sudo rm -rf /usr/local/lib/python3.8/site-packages/cv2*

    Очистите кэш пакета:

sudo apt-get clean

После выполнения этих шагов все установленные библиотеки и зависимости OpenCV будут удалены из вашей системы.





//--------------------------------------------------------------------------------
13.05.2024
разобраться с работой сети EasyCNN
что я хочу понять?

//--------------------------------------------------------------------------------
как загружается изображения?
создаём вектор типа image_t. передаём имя файла с картинками и вектор
	std::vector<image_t> images;
	success = load_mnist_images(mnist_train_images_file, images);

открываем файл для чтения в бинарнов виде. читаем с последнего места указателя в файле.
	std::ifstream ifs(file_path,std::ios::binary);

считываем из начала файла структурную информацию
	ifs.read((char*)&images_total_count, sizeof(images_total_count));
	ifs.read((char*)&magic_number, sizeof(magic_number));
	ifs.read((char*)&height, sizeof(height));
	ifs.read((char*)&width, sizeof(width));

копируем в вектор все картинки из файла.
	for (uint32_t i = 0; i < images_total_count;i++)
	{
		image_t image;
		image.channels = 1;
		image.width = width;
		image.height = height;
		image.data.resize(width*height);
		ifs.read((char*)&image.data[0], width*height);
		images.push_back(image);
	}

struct image_t
{
	size_t width, height, channels;
	std::vector<uint8_t> data;
};

//--------------------------------------------------------------------------------
загружаем данные разметки
	//load train labels
	std::vector<label_t> labels;
	success = load_mnist_labels(mnist_train_labels_file, labels);

копируем все метки из файла вектор.
	for (uint32_t i = 0; i < labels_total_count; i++)
	{
		label_t label;
		ifs.read((char*)&label.data, sizeof(label.data));
		labels.push_back(label);
	}

тип меток просто числа
struct label_t
{
	uint8_t data;
};

//--------------------------------------------------------------------------------
перемешаем элементы в массивах. соответствие индексов в массивах сохраним.
	shuffle_data(images, labels);

	//train data & validate data
	//train
создадим векторы с картинками и метками размером 90% от всей выборки для тренировки
	std::vector<image_t> train_images(static_cast<size_t>(images.size()*0.9f));
	std::vector<label_t> train_labels(static_cast<size_t>(labels.size()*0.9f));
скопируем данные
	std::copy(images.begin(), images.begin() + train_images.size(), train_images.begin());
	std::copy(labels.begin(), labels.begin() + train_labels.size(), train_labels.begin());
	//validate
создадим векторы с картинками и метками размером 10% от всей выборки для проверки
	std::vector<image_t> validate_images(images.size() - train_images.size());
	std::vector<label_t> validate_labels(labels.size() - train_labels.size());
скопируем данные
	std::copy(images.begin() + train_images.size(), images.end(), validate_images.begin());
	std::copy(labels.begin() + train_labels.size(), labels.end(), validate_labels.begin());



	float learningRate = 0.1f;
	const float decayRate = 0.8f;
	const float minLearningRate = 0.001f;
	const size_t testAfterBatches = 50;
	const size_t maxBatches = 10000;
количество полных проходов по всей выборке
	const size_t max_epoch = 5;

### В контексте обучения и выборки, слово "batch" означает следующее:

- **Batch (пакет)**: Это группа или набор данных, который обрабатывается одновременно во время обучения модели машинного обучения.

- **Mini-batch (мини-пакет)**: Это подмножество данных из общего набора данных, которое используется для обновления параметров модели в процессе обучения. Мини-пакеты позволяют эффективно обрабатывать большие объемы данных, улучшая скорость обучения и управляемость процесса.

- **Batch Gradient Descent (градиентный спуск по пакетам)**: Это метод оптимизации, при котором обновление параметров модели происходит после обработки всего набора данных. Это обеспечивает стабильность обновлений, но может быть менее эффективным на больших наборах данных.

- **Mini-batch Gradient Descent (градиентный спуск по мини-пакетам)**: Это метод оптимизации, при котором обновление параметров модели происходит после обработки каждого мини-пакета данных. Этот метод обычно является компромиссом между Batch Gradient Descent и Stochastic Gradient Descent, обеспечивая хорошую скорость обучения и стабильность обновлений.

Использование пакетов и мини-пакетов в процессе обучения модели позволяет эффективно работать с данными и улучшить процесс обучения. Если у вас есть дополнительные вопросы или вам нужна дополнительная информация, не стесняйтесь задавать.
	const size_t batch = 128;

	const size_t channels = images[0].channels;
	const size_t width = images[0].width;
	const size_t height = images[0].height;

//--------------------------------------------------------------------------------
### В контексте обучения и выборки, слово "decayRate" означает следующее:

- **DecayRate (скорость затухания)**: Это параметр, который определяет скорость уменьшения значения определенного параметра в процессе обучения.

- Обычно скорость затухания применяется к learning rate (скорости обучения) или другим параметрам модели для постепенного уменьшения их значений с течением времени.

- Уменьшение learning rate с течением времени может помочь модели сходиться к оптимальному решению, избежать осцилляций и улучшить общее качество обучения.

- Значение decayRate определяет, насколько быстро или медленно параметр будет уменьшаться в процессе обучения.

- Контроль скорости затухания является важным аспектом в настройке гиперпараметров модели для достижения лучших результатов обучения.

Если у вас возникнут дополнительные вопросы или потребуется дополнительная информация, не стесняйтесь обращаться.

//--------------------------------------------------------------------------------
При инициализации сверточных ядер нормальным распределением, каждое ядро получает различные случайные значения. Каждый коэффициент в сверточном ядре инициализируется независимо друг от друга, что приводит к тому, что каждое ядро будет иметь различные значения коэффициентов.

Когда это сверточное ядро применяется к одному и тому же входному вектору в процессе свертки, каждый коэффициент ядра умножается на соответствующий элемент входного вектора, а затем все умноженные значения суммируются. Поскольку коэффициенты в каждом ядре различны, результатом свертки с одним и тем же входным вектором будет различный выходной вектор для каждого ядра.

Таким образом, различные коэффициенты в каждом сверточном ядре, инициализированные из нормального распределения, приводят к различным выходным значениям при свертке с одним и тем же входным вектором.

//--------------------------------------------------------------------------------
Да, в некоторых случаях можно сохранить и использовать предварительно обученные веса первого сверточного слоя при добавлении новых классов без переобучения этого слоя. Этот процесс известен как "перенос обучения" (transfer learning).

В случае переноса обучения, предварительно обученные веса первого сверточного слоя могут содержать общие признаки, которые полезны для новых классов. При добавлении новых классов, вы можете заморозить обучение первого сверточного слоя (то есть не обновлять его веса) и обучить только новые слои, добавленные для новых классов. Это позволит сохранить общие признаки, изученные первым сверточным слоем, и в то же время обучить новые классы.

Однако стоит помнить, что эффективность этого подхода может зависеть от специфики задачи, количества новых классов и данных, а также от того, насколько хорошо общие признаки из первого сверточного слоя подходят для новых классов. Необходимо провести эксперименты и оценить результаты, чтобы определить, насколько хорошо работает перенос обучения в конкретной ситуации.

//--------------------------------------------------------------------------------
создаём объект сети типа: buildConvNet
	EasyCNN::NetWork network(buildConvNet(batch, channels, width, height));
функция создаёт свёрточнуй сеть. фабричный метод.
static EasyCNN::NetWork buildConvNet(const size_t batch,const size_t channels,const size_t width,const size_t height)
{
    // создаём объект нейросети
	EasyCNN::NetWork network;
	// создаём вёдра с пакетами - batch, входными данными и разницей между ними

	const size_t batch = 128;
	const size_t channels = images[0].channels;
	const size_t width = images[0].width;
	const size_t height = images[0].height;
	network.setInputSize(EasyCNN::DataSize(batch, channels, width, height));
принимает объект типа: DataSize size это структура с методами и с полями;
		size_t number = 0;
		size_t channels = 0;
		size_t width = 0;
		size_t height = 0;
	void NetWork::setInputSize(const DataSize size)
помещаем в вектор указатель на корзину с выделенной памятью размером: size
с информацией о размере входных данных.
		dataBuckets.push_back(std::make_shared<DataBucket>(size));
		diffBuckets.push_back(std::make_shared<DataBucket>(size));
поля класса: NetWork
		Phase phase = Phase::Train;
		std::vector<std::shared_ptr<Layer>> layers;
		std::vector<std::shared_ptr<DataBucket>> dataBuckets;
		std::vector<std::shared_ptr<DataBucket>> diffBuckets;
		std::shared_ptr<LossFunctor> lossFunctor;
		std::shared_ptr<Optimizer> optimizer;

	//input data layer
	add_input_layer(network);
создаём указатель и выделяем память для объекта типа: EasyCNN::InputLayer
и помещаем иго в вектор со слоями объекта сети.
		layers.push_back(layer);

	//convolution layer
	add_conv_layer(network, 6 ,1);

	std::shared_ptr<EasyCNN::ConvolutionLayer> convLayer(std::make_shared<EasyCNN::ConvolutionLayer>());
	// создаём свёрточный слой с 6 ядрами 1 канал 3x3.
	// 1, 1 - шаг движения окна свёртки в пикселях
	// true - использовать _enabledBias - использовать смещение
	// EasyCNN::ConvolutionLayer::SAME - при _paddingType типа SAME,
	// для свёртки с крайними, граничными пикселями добавляется незримый ряд пикселей
	convLayer->setParamaters(EasyCNN::ParamSize(number, input_channel, 3, 3), 1, 1, true, EasyCNN::ConvolutionLayer::SAME);
	network.addayer(convLayer);
создаём слой активации и помещаем иго в вектор со слоями объекта сети.
	add_active_layer(network);
	//pooling layer
создаём слой пулинга-субдискретизации и помещаем иго в вектор со слоями объекта сети.
	add_pool_layer(network, 6);
	std::shared_ptr<EasyCNN::PoolingLayer> poolingLayer(std::make_shared<EasyCNN::PoolingLayer>());
установим параметры слоя. MaxPooling, 6 канал, 1 ядер, 2x2, _paddingType типа SAME,
	// 2, 2 - шаг движения окна свёртки в пикселях
	poolingLayer->setParamaters(EasyCNN::PoolingLayer::PoolingType::MaxPooling, EasyCNN::ParamSize(1, number, 2, 2), 2, 2, EasyCNN::PoolingLayer::SAME);
	network.addayer(poolingLayer);

	//convolution layer
	// создаём свёрточный слой с 12 ядрами, 6 каналов, 3x3.
	// 1, 1 - шаг движения окна свёртки в пикселях
	// true - использовать _enabledBias - использовать смещение
	// EasyCNN::ConvolutionLayer::SAME - при _paddingType типа SAME,
	// для свёртки с крайними, граничными пикселями добавляется незримый ряд пикселей
	add_conv_layer(network, 12, 6);
	add_active_layer(network);
	//pooling layer
	add_pool_layer(network, 12);
создаём слой пулинга-субдискретизации и помещаем иго в вектор со слоями объекта сети.
установим параметры слоя. MaxPooling, 1 канал, 12 ядер, 2x2, _paddingType типа SAME,
	// 2, 2 - шаг движения окна свёртки в пикселях

	//full connect layer
полносвязный слой: 1 ядро, 512 каналов, 1x1, _enabledBias
	add_fc_layer(network, 512);
	add_active_layer(network);

	//network.addayer(std::make_shared<EasyCNN::DropoutLayer>(0.5f));

	//full connect layer
	add_fc_layer(network, classes);

	//soft max layer
	add_softmax_layer(network);

	return network;
}


//--------------------------------------------------------------------------------
при добавлении слоёв производится их игициализация в методе: solveInnerParams
	void NetWork::addayer(std::shared_ptr<Layer> layer)
	{
		const auto layer_type = layer->getLayerType();
		logVerbose("NetWork addayer begin , type : %s", layer_type.c_str());
		layers.push_back(layer);

		easyAssert(dataBuckets.size() >= 1, "bucket count is less than 1.");
		const std::shared_ptr<DataBucket> prev = dataBuckets[dataBuckets.size() - 1];
		easyAssert(prev.get() != nullptr, "previous bucket is null.");
		const DataSize inputSize = prev->getSize();
		layer->setPhase(phase);
		layer->setInputBucketSize(inputSize);
		layer->solveInnerParams();
		const DataSize outputSize = layer->getOutputBucketSize();
		//dataBucket setting params
		dataBuckets.push_back(std::make_shared<DataBucket>(outputSize));
		diffBuckets.push_back(std::make_shared<DataBucket>(outputSize));
		logVerbose("NetWork addayer end. add data bucket done.");
	}

//--------------------------------------------------------------------------------

	network.setLossFunctor(std::make_shared<EasyCNN::CrossEntropyFunctor>());
	network.setOptimizer(std::make_shared<EasyCNN::SGD>(learningRate));
	network.setLearningRate(learningRate);

создаём указатели на рабочие массивы корзины с пакетами картинками и метками.
выделяем память в конструкторе
в соответствии с передаваемым объектом: EasyCNN::DataSize(batch, channels, width, height)
вычисляем размер выделяемой памяти. в указатель: data
структура: DataBucket - в начале 4 переменных с размерами описывающими выделенную память
потом сами данные
		DataSize size;
		std::shared_ptr<float> data;
		data(new float[size.totalSize()])
сколько выделяется памяти, вся выборка или один пакет?
один пакет
	std::shared_ptr<EasyCNN::DataBucket> inputDataBucket = std::make_shared<EasyCNN::DataBucket>(EasyCNN::DataSize(batch, channels, width, height));
	std::shared_ptr<EasyCNN::DataBucket> labelDataBucket = std::make_shared<EasyCNN::DataBucket>(EasyCNN::DataSize(batch, classes, 1, 1));


//--------------------------------------------------------------------------------
скопируем один пакет тренировочной выборки в рабочие корзины.
			if (!fetch_data(train_images, inputDataBucket, train_labels, labelDataBucket, batchIdx*batch, batch))
static bool fetch_data(const std::vector<image_t>& images,std::shared_ptr<EasyCNN::DataBucket> inputDataBucket,
	const std::vector<label_t>& labels, std::shared_ptr<EasyCNN::DataBucket> labelDataBucket,
	const size_t offset, const size_t length)

//--------------------------------------------------------------------------------
тренеруем один пакет выборки
			const float batch_loss = network.trainBatch(inputDataBucket,labelDataBucket);

прямой проход по слоям. с входного слоя просто копируем в свёрточный.
		for (size_t i = 0; i < layers.size(); i++)
		{
			logVerbose("NetWork layer[%d](%s) forward begin.", i, layers[i]->getLayerType().c_str());
			if (i < layers.size() - 1)
			{
				dataBuckets[i + 1]->fillData(0.0f);
			}
			layers[i]->forward(dataBuckets[i], dataBuckets[i + 1]);
			logVerbose("NetWork layer[%d](%s) forward end.", i, layers[i]->getLayerType().c_str());
		}



//--------------------------------------------------------------------------------
иницыализация ядер
	void ConvolutionLayer::solveInnerParams()
			kernel.reset(new ParamBucket(kernelSize));
нормальное распределение:
Да, нормальное распределение — это числа, которые создают график гауссианы. График функции плотности вероятности нормального распределения имеет форму колокола, и он симметричен относительно своего среднего значения.
В контексте создания нормального распределения, mean_value означает среднее значение, а standard_deviation — стандартное отклонение. Эти параметры используются для характеристики и моделирования случайных величин, которые подчиняются нормальному распределению.
 если параметр среднего значения установлен в 0, то это значит, что будет создана центрированная выборка?
да.
Стандартное отклонение измеряет разброс значений в выборке вокруг математического ожидания.
			normal_distribution_init(kernel->getData().get(), kernel->getSize().totalSize(), 0.0f, 0.1f);

Kernel Gradient (градиент ядра) в контексте свёрточного ядра — это метод оптимизации, используемый для улучшения производительности свёрточных нейронных сетей. Он основан на градиентном спуске и позволяет автоматически настраивать параметры свёрточного ядра во время обучения сети. Это помогает сети лучше обобщать данные и повышать точность классификации.

			kernelGradient.reset(new ParamBucket(kernel->getSize()));
			const_distribution_init(kernelGradient->getData().get(), kernelGradient->getSize().totalSize(), 0.0f);


//--------------------------------------------------------------------------------
прямой проход.
во входном слое только передаём данные на следующий слой
	void InputLayer::forward(const std::shared_ptr<DataBucket> prev, std::shared_ptr<DataBucket> next)
	{
		prev->cloneTo(*next);
	}

//--------------------------------------------------------------------------------
свёрточный слой.
	static void convolution2d_same(const float* input, const float* kernel, const float* bias, float* output,
		const size_t in, const size_t ic, const size_t iw, const size_t ih,
		const size_t kn, const size_t kw, const size_t kh, const size_t kws, const size_t khs,
		const size_t ow, const size_t oh)
	{
		const DataSize inputSize(in, ic, iw, ih);
		const DataSize kernelSize(kn, ic, kw, kh);
		const DataSize outputSize(in, kn, ow, oh);
		for (size_t nn = 0; nn < in; nn++)
		{
			for (size_t nc = 0; nc < outputSize.channels; nc++)
			{
				for (size_t nh = 0; nh < outputSize.height; nh++)
				{
					for (size_t nw = 0; nw < outputSize.width; nw++)
					{
						const int inStartX = nw - kw/2;
						const int inStartY = nh - kh / 2;
						float sum = 0;
						for (size_t kc = 0; kc < kernelSize.channels; kc++)
						{
							for (size_t kh = 0; kh < kernelSize.height; kh++)
							{
								for (size_t kw = 0; kw < kernelSize.width; kw++)
								{
									const int inY = inStartY + kh;
									const int inX = inStartX + kw;
									if (inY >= 0 && inY<(int)inputSize.height && inX >= 0 && inX<(int)inputSize.width)
									{
										const size_t prevIdx = inputSize.getIndex(nn, kc, inY, inX);
										const size_t kernelIdx = kernelSize.getIndex(nc, kc, kh, kw);
										sum += input[prevIdx] * kernel[kernelIdx];
									}
								}
							}
						}
						if (bias)
						{
							const size_t biasIdx = nc;
							sum += bias[biasIdx];
						}
						const size_t nextIdx = outputSize.getIndex(nn, nc, nh, nw);
						output[nextIdx] = sum;
					}
				}
			}
		}
	}





//--------------------------------------------------------------------------------
14.05.2024
наблюдения.
шесть слоёв мозга
распределение по 6 сторонам
для каждого слоя создавать суперпозицию градиентов закодированную функциями косинуса
для каждого слоя своя частота.
закольцовывание шести слоёв.
разные модальности, такиекак видео, аудио, двигательная и другие использовать как
функции, базисные векторы в суперпространстве, чтобы верифицировать разлогание
векторов в разных измерениях. это как при полиномиальной интерполяции вычисляются
коэффициенты для расширенного пространства, а потом разкладываем вектор в новом
базисе в своей окрестности правдоподобия.
повышение разрешения на основе предположения того, что каждый пиксель как
суперпозиция содержит информацию об окружающих его соседях. вопрос: как эту
информацию извлечь?
a0*x0[i - 1] + a1*x1[i - 1] = x0[i]
a0*x0[i - 1] + a1*x1[i - 1] = x1[i]
векторы сходятся в одной точке приходя из других направлений. угол между векторами
известен. производится линейная комбинация этих векторов и получается сумма, значение
пикселя. задача: получить модули этих векторов под другими углами. как получить
модуль вектора повёрнутого на определённый угол? модуль вектора повёрнутого на
угол альфа равен произведению модуля вектора на косинус угла поворота. если значения
пикселей

a0*x[i - 1]*cos(a) + a1*x[i] + a2*x[i + 1]*cos(a) = x[i]
a0*x1 + a1*x1*cos(a) + a2*x2*cos(a) = x0
a0*x0*cos(a) + a1*x1 + a2*x2*cos(a) = x0

то есть, результат такой интерполяции это точка на плоскости образованной прямоугольником?

Для трехмерных функций существует аналогичный метод, который называется трилинейной интерполяцией. Он представляет значение функции в каждой точке как смесь значений функции в восьми ближайших точках (сверху, снизу, слева, справа, а также угловые точки).

Да, результат билинейной интерполяции — это точка на плоскости, образованной прямоугольником.
 а есть метод интерполяции по ближайшим соседям разлагающий значение каждой точки, как суперпозиции?

Да, существует метод интерполяции по ближайшим соседям, который разлагает значение каждой точки как суперпозицию. Этот метод называется линейной интерполяцией на треугольниках. В нём искомая функция представляется как совокупность плоскостей, определяемых заданными значениями в вершинах треугольников.
 а можешь показать формулы?

К сожалению, я не могу показать формулы, но могу описать принцип работы метода интерполяции по ближайшим соседям.

Этот метод предполагает, что для каждой точки исследуемой области выбирается значение функции, которое имеет ближайшая точка измерения по Евклидову расстоянию. Формула для вычисления оцениваемого значения в точке x выглядит следующим образом:

V∗(x)=∑i=1N​Wi​∑i=1N​Wi​V(xi​)​

где:

    V∗(x) — оцениваемое значение в точке x,

    V(xi​) — известные значения в точках xi​,

    N — количество исходных точек,

    Wi​ — весовые коэффициенты.

 о, это мне и нужно. с помощью подобного метода увеличивают разрешение, чтобы можно было разобрать текст?

Да, с помощью метода интерполяции можно увеличить разрешение изображения, чтобы лучше рассмотреть текст.

//--------------------------------------------------------------------------------
Да, конечно. Вот пример кода на C++, который демонстрирует метод линейной интерполяции на треугольниках:

```cpp
#include <iostream>
#include <vector>
#include <algorithm>

double linear_interpolation(double x, double x0, double x1, double y0, double y1) {
    return y0 + (x - x0) * (y1 - y0) / (x1 - x0);
}

int main() {
    std::vector<std::pair<double, double>> points = {{0.0, 0.0}, {1.0, 1.0}, {2.0, 2.0}, {3.0, 3.0}};

    double x;
    std::cout << "Enter x value to interpolate: ";
    std::cin >> x;

    double y = linear_interpolation(x, points[0].first, points[1].first, points[0].second, points[1].second);
    std::cout << "Interpolated y value: " << y << std::endl;

    return 0;
}
```

В этом коде мы определяем функцию...


//--------------------------------------------------------------------------------


как я понимаю свёртку в алгоритме сети?
в ядро при инициализации помещается выборка нормального распределения. эта выборка
является числами которые строят график гауссианы. он в свою очередь напоминает
положительную полуволну синусоиды. отсюда возникает мысль: а чем отличается произведение
ядра с этим содержимым и матрицей такого же размера как ядро и последующая сумма этих
произведений от произведения вектора входных данных с функциями экспоненты в степенях
частот при преобразовании Фурье? а ни чем по существу. и там и там результатом
является ампоитуда, как результат скалярного произведения векторов или интегралов функций.
разница лишь в том, что во втором случае есть отрицательная полуволна. главная задача
функции "свёртки" в алгоритме нейросети - это поиск линейно независимых базисных векторов
для для разложения в их пространстве признаков входного образа. какая необходимость
искать его каждый раз? а что если попробывать использовать ортогональный базис из
функций косинуса? представить пиксель как вектор градиента разности с окружающими
соседями. получится вектор-последовательность размером в 8 элементов. развернуть эту
последовательность из круга в прямую как вращение вектора против часовой стрелки
показывающее угол. преобразованием Фурье перевести эту последовательность из временной
области в частотную. получить спектр вектора градиентов разности с ближайшими соседями.
это спектр будет инвариантен к повороту. следующая залача: представить топологическую
связь всех одинаковых векторов в пространстве матрицы 3x3. как это сделать? сводить
пулингом всю картинку к минимальной матрице 3x3, суммируя все попадающиеся числа.
если учесть, что мы ищем связь между одинаковыми векторами, то и числа в матрице
картинки для каждого типа векторов будут одинаковыми. следовательно суммирование при
пуллинге будет масштабированием этих искомых векторов. и конечная минимальная матрица
будет характеризовать топологическую связь-плотность этих векторов. в итоге получим
карты топологической связи для всех типов векторов. интересный вопрос: как лучьше
представлять объекты для поиска топологической связи, как одинаковые векторы или
как одинаковые амплитуды частот? если представлять и кодировать частоты, то можно
получить топологическую связь в виде волн во всех направлениям.
//--------------------------------------------------------------------------------
получение вектора градиента разности с окружающими соседями это увеличение изображения
некоторая интерполяция. расширение пространства.
после расширения пространство его можно сжимать обратно проецируя с поправочными
коэффициентами от среднего распределения по классу. таким образом можно сжимать
облако признаков.
//--------------------------------------------------------------------------------
получить топологический градиент. представить признаки одной частоты в виде их
топологического взаимоотношения.
как представить градиент по X и Y?
//--------------------------------------------------------------------------------
сегментировать изображение по плотности облаков признаков. высокая плотность точек облак
в пространстве признаков свидетельствует о наличии объекта-множества. выделять не известный
объект а плотные облака точек в пространстве признаков.
//--------------------------------------------------------------------------------
после прохождения через ортогональный косинусный фильтр получаются некоторые изображения
как результат взаимодействия входного изображения с системой, как некоторая свёртка.
чтобы не вычислять потом много раз косинусные преобразования, можно тренировать сеть
на полученные таким образом изображения как результат работы сложного фильтра. это можно
использовать для моделирования и обучения сети на основе спроектированных ортогональных
фильтрах. сеть не нужно учить всю слой за слоем. каждый слой можно обучать отдельно на
ожидаемый известный результат.



делать пулинг, сжимать пространство не двумерно матрицей 3x3, а в трёхмерном кубе.
так как яркость это третье измерение.

представить топологическую связь пикселей внутри матрицы изобоажения не как одну
матрицу 3x3, отражающую градиент плотности распределения частот, градиентов пикселей,
а как 9 матриц 3x3, каждая из которых будет представлять сектор в матрице.
что это даст?
каждая матрица 3x3 это базисный вектор в признаковом пространстве. это даст большее
обобщение, размытие в топологическом пространсте. даст инвариантность к масштабу.
разделить матрицу на 9 секторов. для каждлй частоты сделать свою характеристику в
каждом секторе матрицы. получим 9 частот, каждая из которых представлена в каждом
секторе.
как частоту представить в разных топологических секторах?






//--------------------------------------------------------------------------------
работа потоков:

создаём лямбда функцию принимающую параметры по ссылке и помещаем адрес в указатель: worker
		auto worker = [&](const size_t start, const size_t stop){
			convolution2d(prevData + start*prevSize._3DSize(), kernelData, biasData, nextData + start*nextSize._3DSize(),
				stop-start, prevSize.channels, prevSize.width, prevSize.height,
				kernelSize.number,kernelSize.width, kernelSize.height, widthStep, heightStep,
				nextSize.width, nextSize.height,(int)padddingType);
		};
		dispatch_worker(worker, prevSize.number);
принимает указатель на функцию и размер входных данных.
	void dispatch_worker(std::function<void(const size_t, const size_t)> func, const size_t number)






//--------------------------------------------------------------------------------
15.05.2024
обучение сети.
		const float loss = backward(labelDataBucket);

Из предоставленного контекста я не могу точно сказать, о каком конкретном алгоритме идет речь. Однако, если рассматривать общий процесс обучения нейронной сети, то ваше понимание в целом верно.

В общем случае процесс обучения нейронной сети включает следующие шаги, которые могут повторяться для каждого слоя:

1. **Forward Pass (Прямой проход)**: Входные данные передаются через нейроны сети, и каждый слой вычисляет выходные значения. В конце получаем предсказанный результат.

2. **Loss Calculation (Вычисление потерь)**: Сравнивается предсказанный результат с ожидаемым значением, и вычисляется ошибка (потеря).

3. **Backward Pass (Обратное распространение)**: На основе ошибки вычисляются градиенты (производные) функции потерь по параметрам сети. Это позволяет определить, как нужно изменить веса, чтобы уменьшить ошибку.

4. **Optimization (Оптимизация)**: С использованием градиентов и выбранного метода оптимизации (например, градиентный спуск), обновляются веса нейронной сети для улучшения ее производительности.

Эти шаги обычно повторяются множество раз (несколько эпох) в процессе обучения нейронной сети. Каждый слой нейронной сети проходит через эти этапы обучения для корректировки своих параметров и улучшения качества предсказаний.

//--------------------------------------------------------------------------------
представить образы-классы как суперпозицию. образ класса состоит из объектов-признаков.
класс как линейная комбинация вектора признаков. признаков по определению меньше чем классов.
сеть нужно обучать не на всей выборке, а на разности между образами одного класса.
сначала создаём базис признакового пространства в котором будем разлагать векторы классов.

если иметь одно абстрактное векторное пространство признаков общее для разных модальностей,
таких как: видео, звук, движение и т.д, то можно воссоздавать генерировать с помощью
автоэнеодера например, из общего пространства признаков классы в каждой каждой модальности
и посылать сгенерированные образы на входы разных модальностей, с тем чтобы получить
максимально близкое по сходству. вектор разлогать в различных пространствах как в
базисных векторах. модальности-пространства как базисные векторы. подавать на вход сети
распознаваемую картинку и сгенерированную после разложения. вычислять разность с центральным
вектором облака признаков конкретного класса. делать это до минимизации расхождения при
поиске класса.

как обучать сеть новым классам не затрагивая уже обученные классы?








//-----------------------------------------------------------------------------------------
21.05.2024
задача:
описать обратный проход по сети.
	float NetWork::backward(const std::shared_ptr<DataBucket> labelDataBucket)
при прямом проходе в функции:
	std::shared_ptr<DataBucket> NetWork::forward(const std::shared_ptr<DataBucket> inputDataBucket)
	сначала передаём данные со входа, то есть изображение на первый слой.
		inputDataBucket->cloneTo(*dataBuckets[0]);
дальше последовательно обрабатываем слои передавая данные с предыдущего к следующему
слою:
			layers[i]->forward(dataBuckets[i], dataBuckets[i + 1]);


получаем данные последнего слоя
		const auto lastOutputData = dataBuckets[dataBuckets.size() - 1];
получаем ошибку-разницу
		const float loss = getLoss(labelDataBucket, lastOutputData);
что делает эта функция?
что содержит labelDataBucket? данные меток для одного пакета
что содержит outputDataBucket? данные последнего слоя. а точнее? что выдаёт последний
слой? какой слой в этой конфигурации последний?
софтмакс. он выдаёт ковариации экспонент значений классов с полносвязного слоя.
функция ошибки. что она делает?
	//cross entropy
	float CrossEntropyFunctor::getLoss(const std::shared_ptr<DataBucket> labelDataBucket,
		const std::shared_ptr<DataBucket> outputDataBucket)


//-----------------------------------------------------------------------------------------
а как тогда можно интерпретировать частное от деления значения с предыдущего слоя на линейную комбинацию единичного вектора в базисе экспонент всех значений с предыдущего слоя? на что это похоже в общем смысле?

### Linear Combinations and Basis Vectors (URL=https://www.3blue1brown.com/lessons/span)
- Частное от деления значения с предыдущего слоя на линейную комбинацию единичного вектора в базисе экспонент всех значений с предыдущего слоя можно интерпретировать как отношение между двумя линейными комбинациями векторов.
- В общем смысле это можно рассматривать как отношение между двумя линейными преобразованиями или композицию линейных операций.
- Это может напоминать пропорцию между двумя линейными пространствами или линейными операторами, где одно пространство или оператор является результатом преобразования другого.
- Интерпретация этого отношения в общем смысле может быть связана с пропорциональностью или зависимостью между двумя линейными структурами или операциями.


### Softmax as a Generalization of Transfer Functions
- Да, можно рассматривать функцию softmax как обобщение импульсной характеристики или передаточной функции системы в контексте нейронных сетей.
- В этом случае входные данные, которые являются результатом предыдущего слоя, могут рассматриваться как входной сигнал для системы.
- Выход текущего слоя, полученный после применения функции softmax, может быть интерпретирован как реакция или выходная характеристика системы на этот входной сигнал.
- Аналогия с импульсной характеристикой или передаточной функцией системы позволяет понимать, как входные данные преобразуются в выходные данные в рамках нейронных сетей, используя функцию softmax для получения вероятностных распределений классов.


``` питон
# Питон

# Предположим, у нас есть выходные данные слоя нейронной сети в виде вектора
выходной_вектор = [0,5, 0,3, 0,2]

# Мы можем интерпретировать этот выходной вектор, используя аналогию передаточных функций
# Допустим, каждый элемент выходного вектора соответствует уровню определенного компонента сигнала

# Аналогично передаточным функциям в системах, мы можем думать о каждом элементе выходного вектора
# как ответ или выход системы на соответствующий компонент входного сигнала

# Например, если выходной вектор равен [0,5, 0,3, 0,2], мы можем интерпретировать это следующим образом:
# - Первый элемент (0,5) представляет собой реакцию системы на первую составляющую входного сигнала.
# - Второй элемент (0,3) представляет собой реакцию системы на вторую составляющую входного сигнала.
# — Третий элемент (0,2) представляет собой реакцию системы на третий компонент входного сигнала.

# Эта интерпретация позволяет нам понять, как уровень нейронной сети обрабатывает и преобразует входные сигналы в выходные ответы.
```

Да, можно считать Softmax обобщением импульсной характеристики и передаточной
функции системы. Входные данные для Softmax — это результат предыдущего слоя,
а выход — текущий слой. Softmax преобразует логиты (наборы чисел) в вероятности,
причём сумма последних равна единице.

что такое логиты?

Логиты — это функция квантиля, связанная со стандартным логистическим распределением
в статистике. Они имеют много применений в анализе данных и машинном обучении,
особенно при преобразовании данных. Математически логит является обратным к
стандартной логистической функции и определяется
как logit(p) = σ^-1(p) = ln(p/(1-p)) для p ∈ (0, 1).

//-----------------------------------------------------------------------------------------
в таком случае, если на выходе софтмакс дисперсия значения одного класса будет
значительно больше дисперсий других классов, то это будет свидетельствоать о
доминировании этого класса в пространстве вектора с выходного слоя. верно?
это напоминает мне метод главных компонент -  pca

### Софтмакс, Дисперсия и Метод Главных Компонент (PCA)
- Если на выходе Softmax функции дисперсия значений одного класса значительно больше дисперсий других классов, это может свидетельствовать о доминировании этого класса в пространстве вектора на выходном слое.
- Подобное доминирование может указывать на то, что модель сильнее уверена в принадлежности к данному классу, чем к другим.
- Сходство с методом главных компонент (PCA) может быть в том, что PCA также используется для анализа дисперсии данных и выделения главных компонент, которые объясняют наибольшее количество дисперсии в данных.
- Оба метода, Softmax и PCA, могут использоваться для анализа и интерпретации данных, но они имеют разные цели и применения в контексте машинного обучения и анализа данных.

в таком случае, верно ли, что в выражении: P(y = i) = exp(z_i) / sum(exp(z_j)), вычисляется ковариация експоненты одного значения слоя с экспонентами всех значений?

Да, верно. В этом выражении вычисляется ковариация экспоненты одного значения слоя с экспонентами всех значений.




